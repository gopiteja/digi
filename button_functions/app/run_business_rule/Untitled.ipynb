{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     239,
     290,
     309,
     348,
     371
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ashyam Zubair\n",
    "Created Date: 14-02-2019\n",
    "\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sqlalchemy\n",
    "import os\n",
    "\n",
    "from MySQLdb._exceptions import OperationalError\n",
    "from sqlalchemy import create_engine, exc\n",
    "from time import time\n",
    "\n",
    "# try:\n",
    "#     from app.ace_logger import Logging\n",
    "# except:\n",
    "#     from ace_logger import Logging\n",
    "     \n",
    "# logging = Logging()\n",
    "\n",
    "import logging\n",
    "class DB(object):\n",
    "    def __init__(self, database, host='127.0.0.1', user='root', password='', port='3306', tenant_id=None):\n",
    "        \"\"\"\n",
    "        Initialization of databse object.\n",
    "\n",
    "        Args:\n",
    "            databse (str): The database to connect to.\n",
    "            host (str): Host IP address. For dockerized app, it is the name of\n",
    "                the service set in the compose file.\n",
    "            user (str): Username of MySQL server. (default = 'root')\n",
    "            password (str): Password of MySQL server. For dockerized app, the\n",
    "                password is set in the compose file. (default = '')\n",
    "            port (str): Port number for MySQL. For dockerized app, the port that\n",
    "                is mapped in the compose file. (default = '3306')\n",
    "        \"\"\"\n",
    "\n",
    "        if host in [\"common_db\",\"extraction_db\", \"queue_db\", \"template_db\", \"table_db\", \"stats_db\", \"business_rules_db\", \"reports_db\"]:\n",
    "            self.HOST = os.environ['HOST_IP']\n",
    "            self.USER = 'root'\n",
    "            self.PASSWORD = os.environ['LOCAL_DB_PASSWORD']\n",
    "            self.PORT = '3306'\n",
    "            self.DATABASE = f'{tenant_id}_{database}' if tenant_id is not None and tenant_id else database\n",
    "        else:\n",
    "            self.HOST = host\n",
    "            self.USER = user\n",
    "            self.PASSWORD = password\n",
    "            self.PORT = port\n",
    "            self.DATABASE = f'{tenant_id}_{database}' if tenant_id is not None and tenant_id else database\n",
    "        \n",
    "        logging.info(f'Host: {self.HOST}')\n",
    "        logging.info(f'User: {self.USER}')\n",
    "        logging.info(f'Password: {self.PASSWORD}')\n",
    "        logging.info(f'Port: {self.PORT}')\n",
    "        logging.info(f'Database: {self.DATABASE}')\n",
    "\n",
    "        self.connect()\n",
    "\n",
    "    def connect(self, max_retry=5):\n",
    "        retry = 1\n",
    "\n",
    "        try:\n",
    "            start = time()\n",
    "            logging.debug(f'Making connection to `{self.DATABASE}`...')\n",
    "            config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{self.DATABASE}?charset=utf8'\n",
    "            self.db_ = create_engine(config, connect_args={'connect_timeout': 2}, pool_recycle=300)\n",
    "            logging.info(f'Engine created for `{self.DATABASE}`')\n",
    "            while retry <= max_retry:\n",
    "                try:\n",
    "                    self.engine = self.db_.connect()\n",
    "                    logging.info(f'Connection established succesfully to `{self.DATABASE}`! ({round(time() - start, 2)} secs to connect)')\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f'Connection failed. Retrying... ({retry}) [{e}]')\n",
    "                    retry += 1\n",
    "                    self.db_.dispose()\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "            return\n",
    "\n",
    "    def execute(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            logging.debug(f'Query: {query}')\n",
    "            data = pd.read_sql(query, engine, index_col='id', **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            logging.warning('Query does not have any value to return.')\n",
    "            return True\n",
    "        except (exc.StatementError, OperationalError) as e:\n",
    "            logging.warning(f'Creating new connection. Engine/Connection is probably None. [{e}]')\n",
    "            self.connect()\n",
    "            data = pd.read_sql(query, self.engine, index_col='id', **kwargs)\n",
    "        except:\n",
    "            logging.exception('Something went wrong executing query. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.where((pd.notnull(data)), None)\n",
    "\n",
    "    def execute_(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data = pd.read_sql(query, engine, **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.replace({pd.np.nan: None})\n",
    "\n",
    "\n",
    "    def insert(self, data, table, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Write records stored in a DataFrame to a SQL database.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame that needs to be write to SQL database.\n",
    "            table (str): The table in which the rcords should be written to.\n",
    "            database (str): The database the table lies in. Leave it none if you\n",
    "                want use database during object creation.\n",
    "            kwargs: Keyword arguments for pandas to_sql function.\n",
    "                See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html\n",
    "                to know the arguments that can be passed.\n",
    "\n",
    "        Returns:\n",
    "            (bool) True is succesfully inserted, else false.\n",
    "        \"\"\"\n",
    "        logging.info(f'Inserting into `{table}`')\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data.to_sql(table, engine, **kwargs)\n",
    "            try:\n",
    "                self.execute(f'ALTER TABLE `{table}` ADD PRIMARY KEY (`id`);')\n",
    "            except:\n",
    "                pass\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception('Something went wrong inserting. Check trace.')\n",
    "            return False\n",
    "\n",
    "    def insert_dict(self, data, table):\n",
    "        \"\"\"\n",
    "        Insert dictionary into a SQL database table.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame that needs to be write to SQL database.\n",
    "            table (str): The table in which the rcords should be written to.\n",
    "\n",
    "        Returns:\n",
    "            (bool) True is succesfully inserted, else false.\n",
    "        \"\"\"\n",
    "        logging.info(f'Inserting dictionary data into `{table}`...')\n",
    "        logging.debug(f'Data:\\n{data}')\n",
    "\n",
    "        try:\n",
    "            column_names = []\n",
    "            params = []\n",
    "\n",
    "            for column_name, value in data.items():\n",
    "                column_names.append(f'`{column_name}`')\n",
    "                params.append(value)\n",
    "\n",
    "            logging.debug(f'Column names: {column_names}')\n",
    "            logging.debug(f'Params: {params}')\n",
    "\n",
    "            columns_string = ', '.join(column_names)\n",
    "            param_placeholders = ', '.join(['%s'] * len(column_names))\n",
    "\n",
    "            query = f'INSERT INTO {table} ({columns_string}) VALUES ({param_placeholders})'\n",
    "\n",
    "            return self.execute(query, params=params)\n",
    "        except:\n",
    "            logging.exception('Error inserting data.')\n",
    "            return False\n",
    "\n",
    "    def update(self, table, update=None, where=None, database=None, force_update=False):\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                self.engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "\n",
    "        logging.info(f'Updating table: `{table}`')\n",
    "        logging.info(f'Update data: `{update}`')\n",
    "        logging.info(f'Where clause data: `{where}`')\n",
    "        logging.info(f'Force update flag: `{force_update}`')\n",
    "\n",
    "        try:\n",
    "            set_clause = []\n",
    "            set_value_list = []\n",
    "            where_clause = []\n",
    "            where_value_list = []\n",
    "\n",
    "            if where is not None and where:\n",
    "                for set_column, set_value in update.items():\n",
    "                    set_clause.append(f'`{set_column}`=%s')\n",
    "                    set_value_list.append(set_value)\n",
    "                set_clause_string = ', '.join(set_clause)\n",
    "            else:\n",
    "                logging.error(f'Update dictionary is None/empty. Must have some update clause.')\n",
    "                return False\n",
    "\n",
    "            if where is not None and where:\n",
    "                for where_column, where_value in where.items():\n",
    "                    where_clause.append(f'{where_column}=%s')\n",
    "                    where_value_list.append(where_value)\n",
    "                where_clause_string = ' AND '.join(where_clause)\n",
    "                query = f'UPDATE `{table}` SET {set_clause_string} WHERE {where_clause_string}'\n",
    "            else:\n",
    "                if force_update:\n",
    "                    query = f'UPDATE `{table}` SET {set_clause_string}'\n",
    "                else:\n",
    "                    message = 'Where dictionary is None/empty. If you want to force update every row, pass force_update as True.'\n",
    "                    logging.error(message)\n",
    "                    return False\n",
    "\n",
    "            params = set_value_list + where_value_list\n",
    "            self.execute(query, params=params)\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception('Something went wrong updating. Check trace.')\n",
    "            return False\n",
    "\n",
    "    def get_column_names(self, table, database=None):\n",
    "        \"\"\"\n",
    "        Get all column names from an SQL table.\n",
    "\n",
    "        Args:\n",
    "            table (str): Name of the table from which column names should be extracted.\n",
    "            database (str): Name of the database in which the table lies. Leave\n",
    "                it none if you want use database during object creation.\n",
    "\n",
    "        Returns:\n",
    "            (list) List of headers. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f'Getting column names of table `{table}`')\n",
    "            return list(self.execute(f'SELECT * FROM `{table}`', database))\n",
    "        except:\n",
    "            logging.exception('Something went wrong getting column names. Check trace.')\n",
    "            return\n",
    "\n",
    "    def execute_default_index(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data = pd.read_sql(query, engine, **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while executing query. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.where((pd.notnull(data)), None)\n",
    "\n",
    "\n",
    "    def get_all(self, table, database=None, discard=None):\n",
    "        \"\"\"\n",
    "        Get all data from an SQL table.\n",
    "\n",
    "        Args:\n",
    "            table (str): Name of the table from which data should be extracted.\n",
    "            database (str): Name of the database in which the table lies. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            discard (list): columns to be excluded while selecting all\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data. (None if an error\n",
    "            occurs)\n",
    "        \"\"\"\n",
    "        logging.info(f'Getting all data from `{table}`')\n",
    "        if discard:\n",
    "            logging.info(f'Discarding columns `{discard}`')\n",
    "            columns = list(self.execute_default_index(f'SHOW COLUMNS FROM `{table}`',database).Field)\n",
    "            columns = [col for col in columns if col not in discard]\n",
    "            columns_str = json.dumps(columns).replace(\"'\",'`').replace('\"','`')[1:-1]\n",
    "            return self.execute(f'SELECT {columns_str} FROM `{table}`', database)\n",
    "\n",
    "        return self.execute(f'SELECT * FROM `{table}`', database)\n",
    "\n",
    "    def get_latest(self, data, group_by_col, sort_col):\n",
    "        \"\"\"\n",
    "        Group data by a column containing repeated values and get latest from it by\n",
    "        taking the latest value based on another column.\n",
    "\n",
    "        Example:\n",
    "        Get the latest products\n",
    "            id     product   date\n",
    "            220    6647     2014-09-01\n",
    "            220    6647     2014-10-16\n",
    "            826    3380     2014-11-11\n",
    "            826    3380     2015-05-19\n",
    "            901    4555     2014-09-01\n",
    "            901    4555     2014-11-01\n",
    "\n",
    "        The function will return\n",
    "            id     product   date\n",
    "            220    6647     2014-10-16\n",
    "            826    3380     2015-05-19\n",
    "            901    4555     2014-11-01\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): Pandas DataFrame to query on.\n",
    "            group_by_col (str): Column containing repeated values.\n",
    "            sort_col (str): Column to identify the latest record.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) Contains the latest records. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info('Grouping data...')\n",
    "            logging.info(f'Data: {data}')\n",
    "            logging.info(f'Group by column: {group_by_col}')\n",
    "            logging.info(f'Sort column: {sort_col}')\n",
    "            return data.sort_values(sort_col).groupby(group_by_col).tail(1)\n",
    "        except KeyError as e:\n",
    "            logging.errot(f'Column `{e.args[0]}` does not exist.')\n",
    "            return None\n",
    "        except:\n",
    "            logging.exception('Something went wrong while grouping data.')\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HOST_IP'] = '18.207.230.116'\n",
    "os.environ['LOCAL_DB_USER'] = 'root'\n",
    "os.environ['LOCAL_DB_PASSWORD'] = 'AlgoTeam123'\n",
    "os.environ['LOCAL_DB_PORT'] = '3306'\n",
    "\n",
    "tenant_id = 'test'\n",
    "\n",
    "db_config = {\n",
    "    'host': os.environ['HOST_IP'],\n",
    "    'user': os.environ['LOCAL_DB_USER'],\n",
    "    'password': os.environ['LOCAL_DB_PASSWORD'],\n",
    "    'port': os.environ['LOCAL_DB_PORT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:\n",
      " case_id TX05D5AA7358415 \n",
      "function_params {'stage': ['test_check']} \n",
      "tenant_id test\n",
      "\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_business_rules\n",
      "DEBUG:root:Making connection to `test_business_rules`...\n",
      "INFO:root:Engine created for `test_business_rules`\n",
      "INFO:root:Connection established succesfully to `test_business_rules`! (5.9 secs to connect)\n",
      "DEBUG:root:Query: SELECT * from `sequence_rule_data` where `group` = %s\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_business_rules\n",
      "DEBUG:root:Making connection to `test_business_rules`...\n",
      "INFO:root:Engine created for `test_business_rules`\n",
      "INFO:root:Connection established succesfully to `test_business_rules`! (4.39 secs to connect)\n",
      "DEBUG:root:Query: SELECT * from `data_sources`\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_extraction\n",
      "DEBUG:root:Making connection to `test_extraction`...\n",
      "INFO:root:Engine created for `test_extraction`\n",
      "INFO:root:Connection established succesfully to `test_extraction`! (4.52 secs to connect)\n",
      "DEBUG:root:Query: SELECT * from `ocr` WHERE case_id = %s\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_queues\n",
      "DEBUG:root:Making connection to `test_queues`...\n",
      "INFO:root:Engine created for `test_queues`\n",
      "INFO:root:Connection established succesfully to `test_queues`! (4.43 secs to connect)\n",
      "DEBUG:root:Query: SELECT * from `process_queue` WHERE case_id = %s\n",
      "INFO:root:\n",
      "data got from the tables is\n",
      "\n",
      "INFO:root:{'ocr': {'case_id': 'TX05D5AA7358415', 'Fax_unique_id': 'TX05D5AA7358415', 'Fax_reference_number': 'A078664387', 'Communication_date_time': Timestamp('2019-09-12 03:56:15'), 'highlight': '{}', 'created_date': Timestamp('2019-09-30 14:09:42'), 'Continuity _of_care': '', 'Fax_senders_name': 'ROBIW', 'Sender_Phone_number': '8779401972', 'Sender_Fax_number': '9999999999', 'Service_Provider_Name': 'TEST DATA', 'Service_provider_NPI': '9999999999', 'Service_provider_TIN': '9999999999', 'Service_Provider_Fax_num': '8779401972', 'Service_Provider_Phone_Num': '9999999999', 'Service_Provider_Network': '', 'Service_Provider_Address': '', 'Requesting_Provider_name': 'PURI MD,MUJAMMAD R', 'Requesting_Provider_NPI': '999999999', 'Requesting_Provider_TIN': '9999999999', 'Requesting_Provider_Fax_Num': '9038704443', 'Requesting_Provider_Phone_Num': '9038704665', 'Requesting_Provider_Network': 'INN', 'Requesting_Provider__Address': '', 'Service_facility_name': 'wilson N Jones REGIONAL MRDICAL CENTRE', 'Facility_address': 'Wilson N Jones REGIONAL MEDICAL CENTRE', 'Patient_first_name': 'KERRY', 'Patient_last_name': 'ANGLIN', 'Member_ID': '10572156301', 'DOB': datetime.date(1958, 7, 9), 'State': 'TX', 'Type_of_Service': '', 'Type_of_request': 'Inpatient', 'CPT_Codes': '', 'ICD_Codes': '', 'HCPCS_Codes': 'empty', 'Start_date': datetime.date(2019, 8, 19), 'End_date': None, 'Fax Number': '9999999999', 'Total_Units': '', 'Member_card_id': '7091958', 'CASE_NUMBER': '1234567', 'Load_Date': '', 'Agent': '', 'Bot Comments': '', 'Table': '[]', 'Add_on_Table': '[{\"header\":[\"CPT Code\",\"Total Units\"],\"rowData\":[{\"CPT Code\":\"43644\",\"Total Units\":\"1\"}]}]', 'Service Entry Number': None, 'Primary_diagnosis': '', 'Daignosis_description': '', 'Work_queue': '', 'Admit_date': None, 'Discharge_date': None, 'count': 0, 'Frequency': '0', 'standard_of_measure': '', 'Status': '', 'communication_date_bot': '7:37 PM 8/19/2019', 'decision_info': 'new case', 'remote_id': None, 'last_updated': Timestamp('2019-09-30 14:09:42'), 'Date Of Notice': None, 'method_used': ''}, 'process_queue': {'file_name': None, 'case_id': 'TX05D5AA7358415', 'document_type': 'folder', 'queue': 'reviewCases', 'state': 'reviewCases', 'stats_stage': 'Maker', 'template_name': 'Dummy Template', 'status': 'Successfully applied business rules', 'error_logs': None, 'completed_processes': 3, 'total_processes': 3, 'case_lock': 0, 'failure_status': 0, 'reference_number': None, 'file_path': None, 'source_of_invoice': 'database', 'cluster': None, 'batch_id': None, 'operator': None, 'agent': '', 'ocr_status': None, 'time_spent': '00:00:00', 'last_updated_by': 'maker', 'last_updated': Timestamp('2019-09-30 14:09:43'), 'created_date': Timestamp('2019-09-08 17:30:04'), 'Fax reference number': '', 'Fax_unique_id': 'TX05D5AA7358415', 'communication_date_time': Timestamp('2019-09-08 17:26:15'), 'communication_date_time_bot': '7:37 PM 8/19/2019', 'case_type': 'new case', 'fax_field_extracted_status': '', 'template_prediction_record': '{\"unique\": \"\"}', 'method_used': None}}\n",
      "INFO:root:\n",
      " Evaluating the rule: {'rule_type': 'static', 'function': 'Assign', 'parameters': {'assign_table': {'table': 'ocr', 'column': 'Fax_reference_number'}, 'assign_value': {'source': 'input', 'value': '99'}}} \n",
      "\n",
      "INFO:root:\n",
      "Evaluating the rule \n",
      "{'rule_type': 'static', 'function': 'Assign', 'parameters': {'assign_table': {'table': 'ocr', 'column': 'Fax_reference_number'}, 'assign_value': {'source': 'input', 'value': '99'}}}\n",
      "\n",
      "DEBUG:root:parameters got are {'assign_table': {'table': 'ocr', 'column': 'Fax_reference_number'}, 'assign_value': {'source': 'input', 'value': '99'}}\n",
      "INFO:root:\n",
      "PARAM OBJECT IS {'source': 'input', 'value': '99'}\n",
      "\n",
      "INFO:root:Updated the data source with the values ocr Fax_reference_number\n",
      " \n",
      "INFO:root:updated the changed fields\n",
      " changed_fields are {'ocr': {'Fax_reference_number': '99'}}\n",
      "INFO:root:\n",
      " Output: True \n",
      "\n",
      "INFO:root:\n",
      "changed fields are \n",
      "{'ocr': {'Fax_reference_number': '99'}}\n",
      "\n",
      "INFO:root:\n",
      " updates from the group rules are \n",
      "{'ocr': {'Fax_reference_number': '99'}}\n",
      "\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_extraction\n",
      "DEBUG:root:Making connection to `test_extraction`...\n",
      "INFO:root:Engine created for `test_extraction`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rules                                           rule_string  \\\n",
      "id                                                      \n",
      "61  {\"rule_type\": \"static\", \"function\": \"Assign\", ...   \n",
      "\n",
      "                                          description rule_id next_if_sucess  \\\n",
      "id                                                                             \n",
      "61  Checking Length of Sender_Phone_number and if ...                          \n",
      "\n",
      "   next_if_failure       group stage rule_name data_source  \n",
      "id                                                          \n",
      "61               3  test_check                              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Connection established succesfully to `test_extraction`! (4.69 secs to connect)\n",
      "INFO:root:Host: 18.207.230.116\n",
      "INFO:root:User: root\n",
      "INFO:root:Password: AlgoTeam123\n",
      "INFO:root:Port: 3306\n",
      "INFO:root:Database: test_queues\n",
      "DEBUG:root:Making connection to `test_queues`...\n",
      "INFO:root:Engine created for `test_queues`\n",
      "INFO:root:Connection established succesfully to `test_queues`! (5.19 secs to connect)\n",
      "INFO:root:Updating table: `ocr`\n",
      "INFO:root:Update data: `{'Fax_reference_number': '99'}`\n",
      "INFO:root:Where clause data: `{'case_id': 'TX05D5AA7358415'}`\n",
      "INFO:root:Force update flag: `False`\n",
      "DEBUG:root:Query: UPDATE `ocr` SET `Fax_reference_number`=%s WHERE case_id=%s\n",
      "WARNING:root:Query does not have any value to return.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flag': True,\n",
       " 'message': 'Applied business rules successfully.',\n",
       " 'updates': {'ocr': {'Fax_reference_number': '99'}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %load apply_business_rule.py\n",
    "import logging # uncomment for local testing\n",
    "logger=logging.getLogger() # uncomment for local testing\n",
    "logger.setLevel(logging.DEBUG) # uncomment for local testing\n",
    "# comment below two for local testing\n",
    "# from ace_logger import Logging\n",
    "# logging = Logging()\n",
    "import json\n",
    "import os\n",
    "\n",
    "from BusinessRules import BusinessRules\n",
    "\n",
    "# one configuration\n",
    "db_config = {\n",
    "    'host': os.environ['HOST_IP'],\n",
    "    'user': os.environ['LOCAL_DB_USER'],\n",
    "    'password': os.environ['LOCAL_DB_PASSWORD'],\n",
    "    'port': os.environ['LOCAL_DB_PORT']\n",
    "}\n",
    "\n",
    "def get_data_sources(tenant_id, case_id, master=False):\n",
    "    \"\"\"Helper to get all the required table data for the businesss rules to apply\n",
    "    \"\"\"\n",
    "    get_datasources_query = \"SELECT * from `data_sources`\"\n",
    "    business_rules_db = DB('business_rules', tenant_id=tenant_id, **db_config)\n",
    "    data_sources = business_rules_db.execute(get_datasources_query)\n",
    "\n",
    "    # case_id based\n",
    "    case_id_based_sources = json.loads(list(data_sources['case_id_based'])[0])\n",
    "    \n",
    "    data = {}\n",
    "    for database, tables in case_id_based_sources.items():\n",
    "        db = DB(database, tenant_id=tenant_id, **db_config)\n",
    "        for table in tables:\n",
    "            if master:\n",
    "                query = f\"SELECT * from `{table}`\"\n",
    "                df = db.execute(query)\n",
    "            else:\n",
    "                query = f\"SELECT * from `{table}` WHERE case_id = %s\"\n",
    "                params = [case_id]\n",
    "                df = db.execute(query, params=params)\n",
    "            if not df.empty:\n",
    "                data[table] = df.to_dict(orient='records')[0]\n",
    "            else:\n",
    "                data[table] = {}\n",
    "    \n",
    "    \n",
    "    case_id_based_sources = json.loads(list(data_sources['case_id_based'])[0])\n",
    "    \n",
    "    return data\n",
    "                \n",
    "def get_rules(tenant_id, group):\n",
    "    \"\"\"Get the rules based on the stage, tenant_id\"\"\"\n",
    "    business_rules_db = DB('business_rules', tenant_id=tenant_id, **db_config)\n",
    "    get_rules_query = \"SELECT * from `sequence_rule_data` where `group` = %s\"\n",
    "    params = [group]\n",
    "    rules = business_rules_db.execute(get_rules_query, params=params)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def run_group_rules(case_id, rules, data):\n",
    "    \"\"\"Run the rules\"\"\"\n",
    "    rules = [json.loads(rule) for rule in list(rules['rule_string'])] \n",
    "    BR  = BusinessRules(case_id, rules, data)\n",
    "    updates = BR.evaluate_business_rules()\n",
    "    \n",
    "    logging.info(f\"\\n updates from the group rules are \\n{updates}\\n\")\n",
    "    return updates\n",
    "\n",
    "def apply_business_rule(case_id, function_params, tenant_id):\n",
    "    \"\"\"Run the business rules based on the stage in function params and tenant_id\n",
    "    Args:\n",
    "        case_id: Unique id that we pass\n",
    "        function_params: Parameters that we get from the configurations\n",
    "        tenant_id: Tenant on which we have to apply the rules\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    updates = {} # keep a track of updates that are being made by business rules\n",
    "    try:\n",
    "        # get the stage from the function_parameters...As of now its first ele..\n",
    "        # need to make generic or key-value pairs\n",
    "        logging.info(f\"\\n case_id {case_id} \\nfunction_params {function_params} \\ntenant_id {tenant_id}\\n\")\n",
    "        stage = function_params['stage'][0]\n",
    "        \n",
    "        \n",
    "        # get the rules\n",
    "        rules = get_rules(tenant_id, stage)\n",
    "        \n",
    "        # get the mapping of the rules...basically a rule_id maps to a rule.\n",
    "        # useful for the chain rule evaluations\n",
    "        rule_id_mapping = {}\n",
    "        for ind, rule in rules.iterrows():\n",
    "            rule_id_mapping[rule['rule_id']] = [rule['rule_string'], rule['next_if_sucess'], rule['next_if_failure'], rule['stage'], rule['description'], rule['data_source']]\n",
    "\n",
    "        # making it generic takes to take a type parameter from the database..\n",
    "        # As of now make it (all others  or chained) only\n",
    "        is_chain_rule = '' not in rule_id_mapping\n",
    "        \n",
    "        # get the required table data on which we will be applying business_rules  \n",
    "        data_tables = get_data_sources(tenant_id, case_id) \n",
    "        \n",
    "        logging.info(f\"\\ndata got from the tables is\\n\")\n",
    "        logging.info(data_tables)\n",
    "        # get the master data if needed\n",
    "        \n",
    "        # apply business rules\n",
    "        if is_chain_rule:\n",
    "            # updates = run_chained_rules()\n",
    "            pass\n",
    "        else:\n",
    "            print ('rules', rules)\n",
    "            updates = run_group_rules(case_id, rules, data_tables)\n",
    "            \n",
    "        \n",
    "        # update in the database, the changed fields eventually when all the stage rules were got\n",
    "        extraction_db = DB('extraction', tenant_id=tenant_id, **db_config) # only in ocr or process_queue we are updating\n",
    "        queue_db = DB('queues', tenant_id=tenant_id, **db_config) # only in ocr or process_queue we are updating\n",
    "        \n",
    "        for table, colum_values in updates.items():\n",
    "            if table == 'ocr':\n",
    "                extraction_db.update(table, update=colum_values, where={'case_id':case_id})\n",
    "            if table == 'process_queue':\n",
    "                queue_db.update(table, update=colum_values, where={'case_id':case_id})\n",
    "        \n",
    "        #  return the updates for viewing\n",
    "        return {'flag': True, 'message': 'Applied business rules successfully.', 'updates':updates}\n",
    "    except Exception as e:\n",
    "        logging.exception('Something went wrong while applying business rules. Check trace.')\n",
    "        return {'flag': False, 'message': 'Something went wrong saving changes. Check logs.', 'error':str(e)}\n",
    "        \n",
    "    \n",
    "case_id = 'TX05D5AA7358415'\n",
    "function_params = {'stage':['test_check']} \n",
    "tenant_id = 'test'\n",
    "apply_business_rule(case_id, function_params, tenant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
