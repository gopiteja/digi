{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     239,
     290,
     309,
     348,
     371
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ashyam Zubair\n",
    "Created Date: 14-02-2019\n",
    "\"\"\"\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import sqlalchemy\n",
    "import os\n",
    "\n",
    "from MySQLdb._exceptions import OperationalError\n",
    "from sqlalchemy import create_engine, exc\n",
    "from time import time\n",
    "\n",
    "# try:\n",
    "#     from app.ace_logger import Logging\n",
    "# except:\n",
    "#     from ace_logger import Logging\n",
    "     \n",
    "# logging = Logging()\n",
    "\n",
    "import logging\n",
    "class DB(object):\n",
    "    def __init__(self, database, host='127.0.0.1', user='root', password='', port='3306', tenant_id=None):\n",
    "        \"\"\"\n",
    "        Initialization of databse object.\n",
    "\n",
    "        Args:\n",
    "            databse (str): The database to connect to.\n",
    "            host (str): Host IP address. For dockerized app, it is the name of\n",
    "                the service set in the compose file.\n",
    "            user (str): Username of MySQL server. (default = 'root')\n",
    "            password (str): Password of MySQL server. For dockerized app, the\n",
    "                password is set in the compose file. (default = '')\n",
    "            port (str): Port number for MySQL. For dockerized app, the port that\n",
    "                is mapped in the compose file. (default = '3306')\n",
    "        \"\"\"\n",
    "\n",
    "        if host in [\"common_db\",\"extraction_db\", \"queue_db\", \"template_db\", \"table_db\", \"stats_db\", \"business_rules_db\", \"reports_db\"]:\n",
    "            self.HOST = os.environ['HOST_IP']\n",
    "            self.USER = 'root'\n",
    "            self.PASSWORD = os.environ['LOCAL_DB_PASSWORD']\n",
    "            self.PORT = '3306'\n",
    "            self.DATABASE = f'{tenant_id}_{database}' if tenant_id is not None and tenant_id else database\n",
    "        else:\n",
    "            self.HOST = host\n",
    "            self.USER = user\n",
    "            self.PASSWORD = password\n",
    "            self.PORT = port\n",
    "            self.DATABASE = f'{tenant_id}_{database}' if tenant_id is not None and tenant_id else database\n",
    "        \n",
    "        logging.info(f'Host: {self.HOST}')\n",
    "        logging.info(f'User: {self.USER}')\n",
    "        logging.info(f'Password: {self.PASSWORD}')\n",
    "        logging.info(f'Port: {self.PORT}')\n",
    "        logging.info(f'Database: {self.DATABASE}')\n",
    "\n",
    "        self.connect()\n",
    "\n",
    "    def connect(self, max_retry=5):\n",
    "        retry = 1\n",
    "\n",
    "        try:\n",
    "            start = time()\n",
    "            logging.debug(f'Making connection to `{self.DATABASE}`...')\n",
    "            config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{self.DATABASE}?charset=utf8'\n",
    "            self.db_ = create_engine(config, connect_args={'connect_timeout': 2}, pool_recycle=300)\n",
    "            logging.info(f'Engine created for `{self.DATABASE}`')\n",
    "            while retry <= max_retry:\n",
    "                try:\n",
    "                    self.engine = self.db_.connect()\n",
    "                    logging.info(f'Connection established succesfully to `{self.DATABASE}`! ({round(time() - start, 2)} secs to connect)')\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    logging.warning(f'Connection failed. Retrying... ({retry}) [{e}]')\n",
    "                    retry += 1\n",
    "                    self.db_.dispose()\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "            return\n",
    "\n",
    "    def execute(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            logging.debug(f'Query: {query}')\n",
    "            data = pd.read_sql(query, engine, index_col='id', **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            logging.warning('Query does not have any value to return.')\n",
    "            return True\n",
    "        except (exc.StatementError, OperationalError) as e:\n",
    "            logging.warning(f'Creating new connection. Engine/Connection is probably None. [{e}]')\n",
    "            self.connect()\n",
    "            data = pd.read_sql(query, self.engine, index_col='id', **kwargs)\n",
    "        except:\n",
    "            logging.exception('Something went wrong executing query. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.where((pd.notnull(data)), None)\n",
    "\n",
    "    def execute_(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data = pd.read_sql(query, engine, **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.replace({pd.np.nan: None})\n",
    "\n",
    "\n",
    "    def insert(self, data, table, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Write records stored in a DataFrame to a SQL database.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame that needs to be write to SQL database.\n",
    "            table (str): The table in which the rcords should be written to.\n",
    "            database (str): The database the table lies in. Leave it none if you\n",
    "                want use database during object creation.\n",
    "            kwargs: Keyword arguments for pandas to_sql function.\n",
    "                See https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html\n",
    "                to know the arguments that can be passed.\n",
    "\n",
    "        Returns:\n",
    "            (bool) True is succesfully inserted, else false.\n",
    "        \"\"\"\n",
    "        logging.info(f'Inserting into `{table}`')\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data.to_sql(table, engine, **kwargs)\n",
    "            try:\n",
    "                self.execute(f'ALTER TABLE `{table}` ADD PRIMARY KEY (`id`);')\n",
    "            except:\n",
    "                pass\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception('Something went wrong inserting. Check trace.')\n",
    "            return False\n",
    "\n",
    "    def insert_dict(self, data, table):\n",
    "        \"\"\"\n",
    "        Insert dictionary into a SQL database table.\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): The DataFrame that needs to be write to SQL database.\n",
    "            table (str): The table in which the rcords should be written to.\n",
    "\n",
    "        Returns:\n",
    "            (bool) True is succesfully inserted, else false.\n",
    "        \"\"\"\n",
    "        logging.info(f'Inserting dictionary data into `{table}`...')\n",
    "        logging.debug(f'Data:\\n{data}')\n",
    "\n",
    "        try:\n",
    "            column_names = []\n",
    "            params = []\n",
    "\n",
    "            for column_name, value in data.items():\n",
    "                column_names.append(f'`{column_name}`')\n",
    "                params.append(value)\n",
    "\n",
    "            logging.debug(f'Column names: {column_names}')\n",
    "            logging.debug(f'Params: {params}')\n",
    "\n",
    "            columns_string = ', '.join(column_names)\n",
    "            param_placeholders = ', '.join(['%s'] * len(column_names))\n",
    "\n",
    "            query = f'INSERT INTO {table} ({columns_string}) VALUES ({param_placeholders})'\n",
    "\n",
    "            return self.execute(query, params=params)\n",
    "        except:\n",
    "            logging.exception('Error inserting data.')\n",
    "            return False\n",
    "\n",
    "    def update(self, table, update=None, where=None, database=None, force_update=False):\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                self.engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "\n",
    "        logging.info(f'Updating table: `{table}`')\n",
    "        logging.info(f'Update data: `{update}`')\n",
    "        logging.info(f'Where clause data: `{where}`')\n",
    "        logging.info(f'Force update flag: `{force_update}`')\n",
    "\n",
    "        try:\n",
    "            set_clause = []\n",
    "            set_value_list = []\n",
    "            where_clause = []\n",
    "            where_value_list = []\n",
    "\n",
    "            if where is not None and where:\n",
    "                for set_column, set_value in update.items():\n",
    "                    set_clause.append(f'`{set_column}`=%s')\n",
    "                    set_value_list.append(set_value)\n",
    "                set_clause_string = ', '.join(set_clause)\n",
    "            else:\n",
    "                logging.error(f'Update dictionary is None/empty. Must have some update clause.')\n",
    "                return False\n",
    "\n",
    "            if where is not None and where:\n",
    "                for where_column, where_value in where.items():\n",
    "                    where_clause.append(f'{where_column}=%s')\n",
    "                    where_value_list.append(where_value)\n",
    "                where_clause_string = ' AND '.join(where_clause)\n",
    "                query = f'UPDATE `{table}` SET {set_clause_string} WHERE {where_clause_string}'\n",
    "            else:\n",
    "                if force_update:\n",
    "                    query = f'UPDATE `{table}` SET {set_clause_string}'\n",
    "                else:\n",
    "                    message = 'Where dictionary is None/empty. If you want to force update every row, pass force_update as True.'\n",
    "                    logging.error(message)\n",
    "                    return False\n",
    "\n",
    "            params = set_value_list + where_value_list\n",
    "            self.execute(query, params=params)\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception('Something went wrong updating. Check trace.')\n",
    "            return False\n",
    "\n",
    "    def get_column_names(self, table, database=None):\n",
    "        \"\"\"\n",
    "        Get all column names from an SQL table.\n",
    "\n",
    "        Args:\n",
    "            table (str): Name of the table from which column names should be extracted.\n",
    "            database (str): Name of the database in which the table lies. Leave\n",
    "                it none if you want use database during object creation.\n",
    "\n",
    "        Returns:\n",
    "            (list) List of headers. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f'Getting column names of table `{table}`')\n",
    "            return list(self.execute(f'SELECT * FROM `{table}`', database))\n",
    "        except:\n",
    "            logging.exception('Something went wrong getting column names. Check trace.')\n",
    "            return\n",
    "\n",
    "    def execute_default_index(self, query, database=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Executes an SQL query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query that needs to be executed.\n",
    "            database (str): Name of the database to execute the query in. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            params (list/tuple/dict): List of parameters to pass to in the query.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data from the executed\n",
    "            query. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        data = None\n",
    "\n",
    "        # Use new database if a new databse is given\n",
    "        if database is not None:\n",
    "            try:\n",
    "                config = f'mysql://{self.USER}:{self.PASSWORD}@{self.HOST}:{self.PORT}/{database}?charset=utf8'\n",
    "                engine = create_engine(config, pool_recycle=300)\n",
    "            except:\n",
    "                logging.exception(f'Something went wrong while connecting. Check trace.')\n",
    "                return False\n",
    "        else:\n",
    "            engine = self.engine\n",
    "\n",
    "        try:\n",
    "            data = pd.read_sql(query, engine, **kwargs)\n",
    "        except exc.ResourceClosedError:\n",
    "            return True\n",
    "        except:\n",
    "            logging.exception(f'Something went wrong while executing query. Check trace.')\n",
    "            params = kwargs['params'] if 'params' in kwargs else None\n",
    "            return False\n",
    "\n",
    "        return data.where((pd.notnull(data)), None)\n",
    "\n",
    "\n",
    "    def get_all(self, table, database=None, discard=None):\n",
    "        \"\"\"\n",
    "        Get all data from an SQL table.\n",
    "\n",
    "        Args:\n",
    "            table (str): Name of the table from which data should be extracted.\n",
    "            database (str): Name of the database in which the table lies. Leave\n",
    "                it none if you want use database during object creation.\n",
    "            discard (list): columns to be excluded while selecting all\n",
    "        Returns:\n",
    "            (DataFrame) A pandas dataframe containing the data. (None if an error\n",
    "            occurs)\n",
    "        \"\"\"\n",
    "        logging.info(f'Getting all data from `{table}`')\n",
    "        if discard:\n",
    "            logging.info(f'Discarding columns `{discard}`')\n",
    "            columns = list(self.execute_default_index(f'SHOW COLUMNS FROM `{table}`',database).Field)\n",
    "            columns = [col for col in columns if col not in discard]\n",
    "            columns_str = json.dumps(columns).replace(\"'\",'`').replace('\"','`')[1:-1]\n",
    "            return self.execute(f'SELECT {columns_str} FROM `{table}`', database)\n",
    "\n",
    "        return self.execute(f'SELECT * FROM `{table}`', database)\n",
    "\n",
    "    def get_latest(self, data, group_by_col, sort_col):\n",
    "        \"\"\"\n",
    "        Group data by a column containing repeated values and get latest from it by\n",
    "        taking the latest value based on another column.\n",
    "\n",
    "        Example:\n",
    "        Get the latest products\n",
    "            id     product   date\n",
    "            220    6647     2014-09-01\n",
    "            220    6647     2014-10-16\n",
    "            826    3380     2014-11-11\n",
    "            826    3380     2015-05-19\n",
    "            901    4555     2014-09-01\n",
    "            901    4555     2014-11-01\n",
    "\n",
    "        The function will return\n",
    "            id     product   date\n",
    "            220    6647     2014-10-16\n",
    "            826    3380     2015-05-19\n",
    "            901    4555     2014-11-01\n",
    "\n",
    "        Args:\n",
    "            data (DataFrame): Pandas DataFrame to query on.\n",
    "            group_by_col (str): Column containing repeated values.\n",
    "            sort_col (str): Column to identify the latest record.\n",
    "\n",
    "        Returns:\n",
    "            (DataFrame) Contains the latest records. (None if an error occurs)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info('Grouping data...')\n",
    "            logging.info(f'Data: {data}')\n",
    "            logging.info(f'Group by column: {group_by_col}')\n",
    "            logging.info(f'Sort column: {sort_col}')\n",
    "            return data.sort_values(sort_col).groupby(group_by_col).tail(1)\n",
    "        except KeyError as e:\n",
    "            logging.errot(f'Column `{e.args[0]}` does not exist.')\n",
    "            return None\n",
    "        except:\n",
    "            logging.exception('Something went wrong while grouping data.')\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HOST_IP'] = '18.207.230.116'\n",
    "os.environ['LOCAL_DB_USER'] = 'root'\n",
    "os.environ['LOCAL_DB_PASSWORD'] = 'AlgoTeam123'\n",
    "os.environ['LOCAL_DB_PORT'] = '3306'\n",
    "\n",
    "tenant_id = 'test'\n",
    "\n",
    "db_config = {\n",
    "    'host': os.environ['HOST_IP'],\n",
    "    'user': os.environ['LOCAL_DB_USER'],\n",
    "    'password': os.environ['LOCAL_DB_PASSWORD'],\n",
    "    'port': os.environ['LOCAL_DB_PORT']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ace_logger'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d3d2d0a76f9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# from db_utils import DB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mBusinessRules\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBusinessRules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# one configuration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AlgonoxWork\\oasis-main\\button_functions\\app\\run_business_rule\\BusinessRules.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0m_StaticFunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_BooleanReturnFunctions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_AssignFunction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AlgonoxWork\\oasis-main\\button_functions\\app\\run_business_rule\\_StaticFunctions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# comment below two for local testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mace_logger\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mlogging\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogging\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ace_logger'"
     ]
    }
   ],
   "source": [
    "# %load apply_business_rule.py\n",
    "# comment below two for local testing\n",
    "# from ace_logger import Logging\n",
    "# logging = Logging()\n",
    "\n",
    "# uncomment these below lines for local testing\n",
    "import logging \n",
    "logger=logging.getLogger() \n",
    "logger.setLevel(logging.DEBUG) \n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "# from db_utils import DB \n",
    "\n",
    "from BusinessRules import BusinessRules\n",
    "\n",
    "# one configuration\n",
    "db_config = {\n",
    "    'host': os.environ['HOST_IP'],\n",
    "    'user': os.environ['LOCAL_DB_USER'],\n",
    "    'password': os.environ['LOCAL_DB_PASSWORD'],\n",
    "    'port': os.environ['LOCAL_DB_PORT']\n",
    "}\n",
    "\n",
    "def get_data_sources(tenant_id, case_id, master=False):\n",
    "    \"\"\"Helper to get all the required table data for the businesss rules to apply\n",
    "    \"\"\"\n",
    "    get_datasources_query = \"SELECT * from `data_sources`\"\n",
    "    business_rules_db = DB('business_rules', tenant_id=tenant_id, **db_config)\n",
    "    data_sources = business_rules_db.execute(get_datasources_query)\n",
    "\n",
    "    # case_id based\n",
    "    case_id_based_sources = json.loads(list(data_sources['case_id_based'])[0])\n",
    "    \n",
    "    data = {}\n",
    "    for database, tables in case_id_based_sources.items():\n",
    "        db = DB(database, tenant_id=tenant_id, **db_config)\n",
    "        for table in tables:\n",
    "            if master:\n",
    "                query = f\"SELECT * from `{table}`\"\n",
    "                df = db.execute(query)\n",
    "            else:\n",
    "                query = f\"SELECT * from `{table}` WHERE case_id = %s\"\n",
    "                params = [case_id]\n",
    "                df = db.execute(query, params=params)\n",
    "            if not df.empty:\n",
    "                data[table] = df.to_dict(orient='records')[0]\n",
    "            else:\n",
    "                data[table] = {}\n",
    "    \n",
    "    \n",
    "    case_id_based_sources = json.loads(list(data_sources['case_id_based'])[0])\n",
    "    \n",
    "    return data\n",
    "                \n",
    "def get_rules(tenant_id, group):\n",
    "    \"\"\"Get the rules based on the stage, tenant_id\"\"\"\n",
    "    business_rules_db = DB('business_rules', tenant_id=tenant_id, **db_config)\n",
    "    get_rules_query = \"SELECT * from `sequence_rule_data` where `group` = %s\"\n",
    "    params = [group]\n",
    "    rules = business_rules_db.execute(get_rules_query, params=params)\n",
    "    return rules\n",
    "\n",
    "def update_tables(case_id, tenant_id, updates):\n",
    "    \"\"\"Update the values in the database\"\"\"\n",
    "    extraction_db = DB('extraction', tenant_id=tenant_id, **db_config) # only in ocr or process_queue we are updating\n",
    "    queue_db = DB('queues', tenant_id=tenant_id, **db_config) # only in ocr or process_queue we are updating\n",
    "    \n",
    "    for table, colum_values in updates.items():\n",
    "        if table == 'ocr':\n",
    "            extraction_db.update(table, update=colum_values, where={'case_id':case_id})\n",
    "        if table == 'process_queue':\n",
    "            queue_db.update(table, update=colum_values, where={'case_id':case_id})\n",
    "    return \"UPDATED IN THE DATABASE SUCCESSFULLY\"\n",
    "\n",
    "def run_group_rules(case_id, rules, data):\n",
    "    \"\"\"Run the rules\"\"\"\n",
    "    rules = [json.loads(rule) for rule in list(rules['rule_string'])] \n",
    "    BR  = BusinessRules(case_id, rules, data)\n",
    "    updates = BR.evaluate_business_rules()\n",
    "    \n",
    "    logging.info(f\"\\n updates from the group rules are \\n{updates}\\n\")\n",
    "    return updates\n",
    "\n",
    "def apply_business_rule(case_id, function_params, tenant_id):\n",
    "    \"\"\"Run the business rules based on the stage in function params and tenant_id\n",
    "    Args:\n",
    "        case_id: Unique id that we pass\n",
    "        function_params: Parameters that we get from the configurations\n",
    "        tenant_id: Tenant on which we have to apply the rules\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    updates = {} # keep a track of updates that are being made by business rules\n",
    "    try:\n",
    "        # get the stage from the function_parameters...As of now its first ele..\n",
    "        # need to make generic or key-value pairs\n",
    "        logging.info(f\"\\n case_id {case_id} \\nfunction_params {function_params} \\ntenant_id {tenant_id}\\n\")\n",
    "        stage = function_params['stage'][0]\n",
    "        \n",
    "        \n",
    "        # get the rules\n",
    "        rules = get_rules(tenant_id, stage)\n",
    "        \n",
    "        # get the mapping of the rules...basically a rule_id maps to a rule.\n",
    "        # useful for the chain rule evaluations\n",
    "        rule_id_mapping = {}\n",
    "        for ind, rule in rules.iterrows():\n",
    "            rule_id_mapping[rule['rule_id']] = [rule['rule_string'], rule['next_if_sucess'], rule['next_if_failure'], rule['stage'], rule['description'], rule['data_source']]\n",
    "\n",
    "        # making it generic takes to take a type parameter from the database..\n",
    "        # As of now make it (all others  or chained) only\n",
    "        is_chain_rule = '' not in rule_id_mapping\n",
    "        \n",
    "        # get the required table data on which we will be applying business_rules  \n",
    "        data_tables = get_data_sources(tenant_id, case_id) \n",
    "        \n",
    "        logging.info(f\"\\ndata got from the tables is\\n\")\n",
    "        logging.info(data_tables)\n",
    "        # apply business rules\n",
    "        if is_chain_rule:\n",
    "            # updates = run_chained_rules()\n",
    "            pass\n",
    "        else:\n",
    "            updates = run_group_rules(case_id, rules, data_tables)\n",
    "            \n",
    "        \n",
    "        # update in the database, the changed fields eventually when all the stage rules were got\n",
    "        update_tables(case_id, tenant_id, updates)\n",
    "        \n",
    "        #  return the updates for viewing\n",
    "        return {'flag': True, 'message': 'Applied business rules successfully.', 'updates':updates}\n",
    "    except Exception as e:\n",
    "        logging.exception('Something went wrong while applying business rules. Check trace.')\n",
    "        return {'flag': False, 'message': 'Something went wrong while applying business rules. Check logs.', 'error':str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {1:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = {3:4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 4, 1: 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.update(a)\n",
    "c.update(b)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
